{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT PreProcessing and Modeling.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oB_-k5cjwaFu",
        "outputId": "d39b33b4-4822-4160-db98-43494874a173"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.8.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.9,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text) (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.44.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (0.24.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (13.0.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.21.6)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 52.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.14.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (57.4.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (0.5.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (2.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (4.1.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow-text) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.9,>=2.8.0->tensorflow-text) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly, tensorflow-text\n",
            "Successfully installed tensorflow-text-2.8.1 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xYZBjDh5v_sA"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
        "encoder_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\""
      ],
      "metadata": {
        "id": "9yIN8TTGwUgA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocess_model = hub.KerasLayer(preprocess_url) # creating hub layer"
      ],
      "metadata": {
        "id": "6OO2yxuow2I2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`bert_preprocess_model` is a function pointer. Will be performing pre-processing in our raw text. This pre-processing will be accepted by the **BERT** model. "
      ],
      "metadata": {
        "id": "nDClRtiJxjYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_test = ['This is a notebook','This is BERT model'] # sample text\n",
        "text_preprocessed = bert_preprocess_model(text_test) # dictionary\n",
        "text_preprocessed.keys() # the keys in dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAqLkLSKw5sr",
        "outputId": "b616fc5d-30fb-45dd-b1ff-20705bd969d2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_word_ids', 'input_type_ids', 'input_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_test[0].split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMVCU6trzQ6y",
        "outputId": "6e698d3d-db44-420a-8ebe-54995d2648cb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_preprocessed['input_word_ids'] # The first sentence has 4 words but this vector has marked 6 words "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvLCxkidxHd8",
        "outputId": "5f8dae6d-df27-43f6-9e16-2f829c1717c2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
              "array([[  101,  2023,  2003,  1037, 14960,   102,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [  101,  2023,  2003, 14324,  2944,   102,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AS BERT WILL PUT SPACIAL TOKEN CALLED **CLS** IN THE BEGINNING AND **SEP** AT THE END TO SEPERATE TWO SENTENCES.\n",
        "\n",
        "'CLS This is a notebook SEP'\n",
        "\n",
        "'CLS This is BERT model SEP'"
      ],
      "metadata": {
        "id": "dk37HE7L0P6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "text_preprocessed['input_type_ids']"
      ],
      "metadata": {
        "id": "G0w3cWgrzLqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_preprocessed['input_mask']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za_2KzAQ0oea",
        "outputId": "570b06a2-3e3e-482a-d46e-f1b99cfc35e5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
              "array([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = hub.KerasLayer(encoder_url) # function pointer to the model"
      ],
      "metadata": {
        "id": "DVRfYrwD13lp"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_results = bert_model(text_preprocessed) # supplying pre-processed text\n",
        "bert_results.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92yCyP3A1_fh",
        "outputId": "246985ee-9ea5-4947-cfa7-8f9c15037da9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['encoder_outputs', 'default', 'pooled_output', 'sequence_output'])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`pooled_output` is embedding for entire sentences. 768 size vector accuratly represents a sentence."
      ],
      "metadata": {
        "id": "HEYKJ2eX8PMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_results['pooled_output'] # sentence embedding vector can be used in NLP task directly."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioOaue6O2Gi5",
        "outputId": "41a04d1c-5c8a-4a25-8b07-9f53045f3f60"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 768), dtype=float32, numpy=\n",
              "array([[-0.85602754, -0.21811046,  0.44990915, ...,  0.40079123,\n",
              "        -0.5726854 ,  0.8601298 ],\n",
              "       [-0.87443405, -0.29097676,  0.0370084 , ..., -0.1664732 ,\n",
              "        -0.56644905,  0.8661555 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# individual word embedding vector\n",
        "bert_results['sequence_output'] # for each word of each sentence it will have 768 size vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw7lhkMs2M6h",
        "outputId": "718e2156-ccf2-4135-af2c-bf435a32f8fe"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
              "array([[[-0.06484351,  0.18709818, -0.08521189, ..., -0.22052334,\n",
              "          0.123952  ,  0.3336754 ],\n",
              "        [-0.5515665 , -0.17585446,  0.5669601 , ..., -0.84280074,\n",
              "          0.5317802 ,  0.37333864],\n",
              "        [ 0.03778867, -0.2596987 ,  0.5838067 , ..., -0.0258976 ,\n",
              "          0.47649878,  1.2347623 ],\n",
              "        ...,\n",
              "        [-0.03841615,  0.04802167,  0.2363291 , ..., -0.03014144,\n",
              "          0.1888106 ,  0.4226545 ],\n",
              "        [-0.01032433,  0.07828996,  0.27397788, ...,  0.04016506,\n",
              "          0.13728039,  0.3544454 ],\n",
              "        [-0.19565459,  0.00866852,  0.28279334, ...,  0.11817306,\n",
              "          0.07485361,  0.32298705]],\n",
              "\n",
              "       [[-0.2806494 ,  0.166391  ,  0.26657495, ..., -0.36268088,\n",
              "          0.12614633,  0.4466243 ],\n",
              "        [-0.6941366 , -0.22901328,  0.45368475, ..., -0.5584245 ,\n",
              "          0.64315647,  0.30351117],\n",
              "        [-0.41080892, -0.5306831 ,  0.6855127 , ..., -0.25293842,\n",
              "          0.32183754,  0.86481696],\n",
              "        ...,\n",
              "        [-0.1968195 ,  0.06129508,  0.64585775, ...,  0.05221655,\n",
              "         -0.01221643,  0.13743222],\n",
              "        [-0.30415702,  0.05438339,  0.65891504, ...,  0.13107657,\n",
              "         -0.05686869,  0.10290026],\n",
              "        [-0.21679418, -0.05760463,  0.69068563, ...,  0.07230134,\n",
              "         -0.07011392,  0.02166949]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have two sentences and for each individual sentence we will have some padding and total 128 length.\n",
        "\n",
        "CLS 423 54 435 545 343 SPE 0 0 0 0 -> 128\n",
        "\n",
        "and we will have 768 size vector for each word(128) in a sentence"
      ],
      "metadata": {
        "id": "qfp2zcR_GHcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# small bert based has 12 encoders\n",
        "len(bert_results['encoder_outputs'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKgZgJpB8nhl",
        "outputId": "81929945-a460-464c-992a-b666421042f4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_results['encoder_outputs'][0] # output of first encoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owdnhn6MJwig",
        "outputId": "4c0418e0-8374-49a2-9f2a-b4a4e0b61005"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
              "array([[[ 0.17943142, -0.02459913, -0.11352944, ...,  0.07549001,\n",
              "          0.02028152,  0.11161339],\n",
              "        [-0.42330408,  0.18787727,  0.04687632, ...,  0.15582815,\n",
              "          0.5990445 ,  0.11757566],\n",
              "        [-1.0326885 , -0.61222714, -0.5654511 , ...,  0.34777492,\n",
              "          0.50954247,  0.6409524 ],\n",
              "        ...,\n",
              "        [-0.12242051, -0.41352063,  0.54070365, ...,  0.2826595 ,\n",
              "         -0.25184885,  0.15229562],\n",
              "        [-0.21878125, -0.41811937,  0.4171768 , ...,  0.30987322,\n",
              "         -0.14763938,  0.0935528 ],\n",
              "        [-0.08114739, -0.36670592,  0.45129043, ...,  0.6468837 ,\n",
              "         -0.47372878,  0.03105961]],\n",
              "\n",
              "       [[ 0.17464432,  0.04171177,  0.00219975, ...,  0.11144857,\n",
              "          0.05800582,  0.05139124],\n",
              "        [-0.4036029 ,  0.49570137,  0.03233614, ...,  0.25487685,\n",
              "          0.5273421 , -0.1384246 ],\n",
              "        [-0.55064833, -0.12166771, -0.4984468 , ...,  0.36268017,\n",
              "          0.33495247,  0.3313707 ],\n",
              "        ...,\n",
              "        [-0.03828631, -0.11720217,  0.5173001 , ...,  0.23810261,\n",
              "         -0.3086776 ,  0.08416538],\n",
              "        [-0.13694352, -0.1255152 ,  0.38273406, ...,  0.2589443 ,\n",
              "         -0.21745819, -0.00626116],\n",
              "        [-0.00728917, -0.09753537,  0.4281227 , ...,  0.59161997,\n",
              "         -0.52679724, -0.07356705]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_results['encoder_outputs'][-1] # output of last encoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "st7EiIBDKdK3",
        "outputId": "22bbcfe0-9868-48b7-8226-7f3f67feae52"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
              "array([[[-0.06484351,  0.18709818, -0.08521189, ..., -0.22052334,\n",
              "          0.123952  ,  0.3336754 ],\n",
              "        [-0.5515665 , -0.17585446,  0.5669601 , ..., -0.84280074,\n",
              "          0.5317802 ,  0.37333864],\n",
              "        [ 0.03778867, -0.2596987 ,  0.5838067 , ..., -0.0258976 ,\n",
              "          0.47649878,  1.2347623 ],\n",
              "        ...,\n",
              "        [-0.03841615,  0.04802167,  0.2363291 , ..., -0.03014144,\n",
              "          0.1888106 ,  0.4226545 ],\n",
              "        [-0.01032433,  0.07828996,  0.27397788, ...,  0.04016506,\n",
              "          0.13728039,  0.3544454 ],\n",
              "        [-0.19565459,  0.00866852,  0.28279334, ...,  0.11817306,\n",
              "          0.07485361,  0.32298705]],\n",
              "\n",
              "       [[-0.2806494 ,  0.166391  ,  0.26657495, ..., -0.36268088,\n",
              "          0.12614633,  0.4466243 ],\n",
              "        [-0.6941366 , -0.22901328,  0.45368475, ..., -0.5584245 ,\n",
              "          0.64315647,  0.30351117],\n",
              "        [-0.41080892, -0.5306831 ,  0.6855127 , ..., -0.25293842,\n",
              "          0.32183754,  0.86481696],\n",
              "        ...,\n",
              "        [-0.1968195 ,  0.06129508,  0.64585775, ...,  0.05221655,\n",
              "         -0.01221643,  0.13743222],\n",
              "        [-0.30415702,  0.05438339,  0.65891504, ...,  0.13107657,\n",
              "         -0.05686869,  0.10290026],\n",
              "        [-0.21679418, -0.05760463,  0.69068563, ...,  0.07230134,\n",
              "         -0.07011392,  0.02166949]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_results['encoder_outputs'][-1] == bert_results['sequence_output']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "De0gADpEKiR3",
        "outputId": "18b983fc-0075-40c5-c34f-4a333be9688e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 128, 768), dtype=bool, numpy=\n",
              "array([[[ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        ...,\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True]],\n",
              "\n",
              "       [[ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        ...,\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True]]])>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output of last `encoder_outputs` will be equal to `sequence_output`"
      ],
      "metadata": {
        "id": "WKXqvBp-KoXw"
      }
    }
  ]
}